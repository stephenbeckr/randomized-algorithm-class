{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo08_higherAccuracyRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM0nnDh76Rx2hCrxaxTAsTa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenbeckr/randomized-algorithm-class/blob/master/Demos/demo08_higherAccuracyRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcXAkDfs6OJD"
      },
      "source": [
        "# High-accuracy sketched least-squares\n",
        "\n",
        "Demo of the \n",
        "1. Iterative Hessian Sketch (IHS) cf. Pilanci and Wainwright; and of the \n",
        "2. preconditioned approaches (BLENDENPIK, LSRN)\n",
        "\n",
        "These are two methods to get high-accuracy l2 regression\n",
        "\n",
        "The goal is to approximate the solution of\n",
        "$$  \\min_{x} \\| Ax-b \\|_2^2 $$\n",
        "where $A$ is $M \\times N$ and we are assuming $M \\gg N$.\n",
        "\n",
        "Code: Stephen Becker, Oct 2021\n",
        "\n",
        "References:\n",
        "- \"Iterative Hessian Sketch: Fast and Accurate Solution\n",
        "Approximation for Constrained Least-Squares\" (Pilanci, Wainwright; JMLR 2016\n",
        "http://www.jmlr.org/papers/volume17/14-460/14-460.pdf )\n",
        "- \"Blendenpik: Supercharging LAPACK's Least-Squares Solver\" (Avron et al. 2010, https://epubs.siam.org/doi/abs/10.1137/090767911); \n",
        "- \"LSRN: A Parallel Iterative Solver for Strongly Over- or Underdetermined Systems\" (Meng et al. 2014, https://epubs.siam.org/doi/abs/10.1137/120866580 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-WX9lSc9XBx"
      },
      "source": [
        "import numpy as np\n",
        "import numpy.linalg\n",
        "from numpy.linalg import norm\n",
        "from numpy.random import default_rng\n",
        "rng = default_rng()\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import scipy.linalg\n",
        "\n",
        "# Download sketching code\n",
        "!wget -q https://raw.githubusercontent.com/stephenbeckr/randomized-algorithm-class/master/Code/sketch.py\n",
        "import sketch as sk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydwuiw9T4CsM"
      },
      "source": [
        "Setup some problem data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmciMdGD9q_v"
      },
      "source": [
        "M, N = int(14e4), int(5e2)\n",
        "# M, N = int(8e4), int(5e2)\n",
        "\n",
        "A   = rng.standard_normal( (M,N) )@np.diag(np.logspace(0,3,N))@(\n",
        "    rng.standard_normal((N,N) ) + 0.1*np.eye(N) )\n",
        "\n",
        "x   = rng.standard_normal( (N,1) )\n",
        "b   = A@x\n",
        "b   += 0.3*norm(b)/np.sqrt(M)*rng.standard_normal( (M,1) ) # add noise\n",
        "# (The larger the noise, the worse sketch-to-solve will perform )"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAU-PEWV4Exa"
      },
      "source": [
        "#### Solve via standard direct solver, nothing randomized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTaJVxq2Ipmv",
        "outputId": "17a6feaa-21ea-4179-8ec8-9f070785a6f6"
      },
      "source": [
        "print(\"Solving via classical dense method\")\n",
        "%time xLS, residLS, rank, singVals = np.linalg.lstsq(A,b,rcond=None)\n",
        "\n",
        "print(f'Condition number of A is {singVals[0]/singVals[-1]:.3e}')\n",
        "\n",
        "AxLS = A@xLS\n",
        "# print(f'Relative residual ||Ax-b||/||b|| is {norm(AxLS-b)/norm(b):.2f}')\n",
        "print(f'Relative residual ||Ax-b||/||b|| is {np.sqrt(residLS[0])/norm(b):.2f}')\n",
        "# and use this to create error metrics\n",
        "def errors(x):\n",
        "  Ax  = np.ravel(A@x)\n",
        "\n",
        "  # Careful: do the ravel() since if we try (n,) - (n,1) then numpy\n",
        "  #   tries to broadcast this to something huge, and isn't what we want.\n",
        "  err1 = norm( Ax-np.ravel(b) )/norm(np.ravel(AxLS)-np.ravel(b))  - 1  # error in objective value\n",
        "  err2 = norm( np.ravel(x) - np.ravel(xLS) )/norm( xLS )     # error in x - xLS (relative error)\n",
        "  err3 = norm( Ax-np.ravel(AxLS) )/norm(AxLS)      # error in IHS analysis\n",
        "  return err1, err2, err3"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving via classical dense method\n",
            "CPU times: user 11.8 s, sys: 473 ms, total: 12.3 s\n",
            "Wall time: 6.68 s\n",
            "Condition number of A is 2.265e+07\n",
            "Relative residual ||Ax-b||/||b|| is 0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lohUWX-S2yt-"
      },
      "source": [
        "#### Make some sketches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_38X8kobjUa"
      },
      "source": [
        "from scipy.sparse.linalg import LinearOperator\n",
        "from scipy.linalg import clarkson_woodruff_transform\n",
        "import scipy.fft\n",
        "# dct = lambda X : scipy.fft.dct( X, norm='ortho', type=2, axis=0)\n",
        "# Note: this is the transpose of Matlab's dct (\"type 2\") actually!\n",
        "# Types 2 and 3 are inverses of each other\n",
        "# It doesn't really matter which kind we use...\n",
        "\n",
        "# axis=0 is VERY IMPORTANT!! otherwise default is axis=-1, the last axis\n",
        "#   so then we get wrong answer when applying to a matrix\n",
        "dct = lambda X : scipy.fft.dct( X, norm='ortho', type=3, axis=0)\n",
        "\n",
        "def MyElementwiseMultiply( d, X):\n",
        "  \"\"\" like d*X aka np.multiply(d,X)\n",
        "  except it handles the case when d is size (n,) and X is size (n,1)\n",
        "  since then naively doing d*X does an outer product since numpy doesn't\n",
        "  consider (n,) and (n,1) to be the same...  but we also want to allow\n",
        "  for the case when X is size (n,)\n",
        "  \"\"\"\n",
        "  if d.ndim == X.ndim:\n",
        "      # Great\n",
        "      y = d*X\n",
        "  elif d.ndim == 1:\n",
        "      y = d.reshape(-1,1) * X\n",
        "  else:\n",
        "      y = d * X.reshape(-1,1)\n",
        "  \n",
        "  return y\n",
        "\n",
        "def MySubsample( X, ind):\n",
        "  \"\"\" like X[ind,:] but works in case X has size (n,) \"\"\"\n",
        "  if X.ndim == 1:\n",
        "      y = X[ind]\n",
        "  elif X.ndim == 2:\n",
        "      y = X[ind,:]\n",
        "  else:\n",
        "      raise ValueError(\"Expected 1D or 2D array\")\n",
        "  return y\n",
        "\n",
        "\n",
        "def FJLT(m, M, rng=np.random.default_rng() ):\n",
        "  d   = np.sign( rng.standard_normal(size=M) ) #.astype( np.int64 )\n",
        "  ind = rng.choice( M, size=m, replace=False, shuffle=False)\n",
        "\n",
        "  fjltMatMat = lambda X : np.sqrt(M/m)*MySubsample( dct( MyElementwiseMultiply(d,X)) , ind)\n",
        "  S   = LinearOperator( (m,M), matvec = fjltMatMat, matmat = fjltMatMat )\n",
        "  return S"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIhugSMX29EV"
      },
      "source": [
        "### Choose a sketch to use\n",
        "Usually choose FJLT, but could choose Gaussian (if problem isn't too big) or CountSketch (if problem is huge)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTWGiD0gZa4t",
        "outputId": "f67ac13c-f6a2-4589-d58d-144553e74f30"
      },
      "source": [
        "%%time\n",
        "m   = 40*N  # sketch size\n",
        "print(f\"m is {m}, M is {M}, N is {N}\")\n",
        "\n",
        "if M < 1e4 and False:\n",
        "  # This runs out of memory if M is too large\n",
        "  S   = sk.Gaussian( (m,M) )\n",
        "  #S   = rng.standard_normal( (m,M) )/np.sqrt(m)\n",
        "  SA  = S@A\n",
        "  Sb  = S@b\n",
        "  print('Using a Gaussian sketch')\n",
        "\n",
        "elif False:\n",
        "  # == Use a count-sketch:\n",
        "  # SAb = clarkson_woodruff_transform( np.hstack( (A,b) ), m )\n",
        "  # SA  = SAb[:,:-1]\n",
        "  # Sb  = SAb[:,-1]\n",
        "  S   = sk.Count( (m,M) )\n",
        "  print('Using a Count sketch')\n",
        "\n",
        "else:\n",
        "  # == ... or try a FJLT ...\n",
        "  # S   = FJLT(m,M,rng)\n",
        "  S   = sk.FJLT( (m,M) )\n",
        "\n",
        "  # SA  = S@A\n",
        "  # Sb  = S@b\n",
        "  print('Using a FJLT sketch')\n",
        "\n",
        "SA  = S@A\n",
        "Sb  = S@b\n",
        "print(f'||Sb||/||b|| is {norm(Sb)/norm(b):.4f}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m is 20000, M is 140000, N is 500\n",
            "Using a FJLT sketch\n",
            "||Sb||/||b|| is 0.9970\n",
            "CPU times: user 3.26 s, sys: 335 ms, total: 3.6 s\n",
            "Wall time: 3.59 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eLg0IALaPIa"
      },
      "source": [
        "def full_sketch( SA, Sb, cond=1e-12,columnVec = True):\n",
        "  \"\"\" SA should be S@A and Sb should be S@b \n",
        "  Solves  min_x || S(Ax-b) ||_2 \"\"\"\n",
        "  # return np.linalg.lstsq(SA,Sb,rcond=None)[0]\n",
        "  x = scipy.linalg.lstsq(SA,Sb,cond=cond,lapack_driver='gelsd')[0]\n",
        "  if columnVec:\n",
        "    return np.reshape( x, (-1,1) ) # make sure it is (n,1) not (n,)\n",
        "  else:\n",
        "    # it will have the same shape convention as Sb, so if Sb is (m,1)\n",
        "    #   then x will be (n,1) and if Sb is (m,) then x will be (n,)\n",
        "    return x\n",
        "\n",
        "def partial_sketch(SA,Atb, printOutput=False, solver=0, reg=0,columnVec = True):\n",
        "  \"\"\" SA should be S@A and Atb should be A.T@b \n",
        "  Solves min_x ||SAx||_2^2 - 2<x,A^T b>,\n",
        "  i.e., x = ( (SA)^T SA )^{-1} A^T b\n",
        "  \n",
        "  Solver choices:\n",
        "    solver=0  is using scipy.linalg.solve on (SA)^T(SA) which is fast\n",
        "      but less accurate since it square the condition number of SA,\n",
        "      so recommended for all but the most ill-conditioned problems.\n",
        "      Set reg>0 (e.g., reg=1e-10) to add a small amount of regularization\n",
        "      (relative to the largest singular value)\n",
        "\n",
        "    solver=1  uses a pivoted QR decomposition and is more appropriate when\n",
        "      the matrix is ill-conditioned, but a bit slower.  `reg` has no effect\n",
        "\n",
        "    solver=2  uses an unpivoted QR decomposition and is a bit faster than\n",
        "      solver=1.  `reg` has no effect\n",
        "   \"\"\"\n",
        "  \n",
        "  if solver == 0:\n",
        "    # == Below is the basic code that fails if ill-conditioned: ==\n",
        "    if reg is None or reg==0:\n",
        "      x = scipy.linalg.solve(  SA.T@SA, Atb, assume_a='pos')\n",
        "    else:\n",
        "      # == Slightly better for ill-conditioned, still not good at all though ==\n",
        "      G = SA.T@SA\n",
        "      normG = norm(G,ord=2)\n",
        "      if printOutput:\n",
        "        print(f\"||G|| is {normG:.2e} and has condition number {np.linalg.cond(G):.2e}\")\n",
        "      # Add in a bit of regularization:\n",
        "      x = scipy.linalg.solve(  G + reg*normG*np.eye(N), Atb, assume_a='pos')\n",
        "  elif solver == 1:\n",
        "    # == The above still has problems when ill-conditioned. Let's do SA = QR\n",
        "    # Then G = R^T R and we can do back substitution\n",
        "    R, perm = scipy.linalg.qr( SA, mode='r', pivoting=True )\n",
        "    R = R[:N,:] # Annoyingly, in mode='r', R is rectangular not square, but 'economic' mode is slow.\n",
        "\n",
        "    y = scipy.linalg.solve_triangular( R, Atb[perm], trans='T')\n",
        "    x = np.zeros_like(y)\n",
        "    x[perm] = scipy.linalg.solve_triangular( R, y, trans='N')\n",
        "\n",
        "  elif solver == 2:\n",
        "    # == Same as solver==1 but no pivoting, and use numpy not scipy\n",
        "    #  since it gives us thin factorization (but doesn't support pivoting)\n",
        "    R = numpy.linalg.qr( SA, mode='r')\n",
        "    y = scipy.linalg.solve_triangular( R, Atb, trans='T')\n",
        "    x = scipy.linalg.solve_triangular( R, y, trans='N')\n",
        "\n",
        "  if printOutput:\n",
        "    res = norm( SA.T@(SA@x) - Atb )/norm(Atb)\n",
        "    print(f'Relative residual ||(SA)^T (SA)x - A^T b||/||A^T b|| is {res:.2e}')\n",
        "\n",
        "  if columnVec:\n",
        "    return np.reshape( x, (-1,1) ) # make sure it is (n,1) not (n,)\n",
        "  else:\n",
        "    # it will have the same shape convention as Sb, so if Sb is (m,1)\n",
        "    #   then x will be (n,1) and if Sb is (m,) then x will be (n,)\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueJ8T0iC3WVy"
      },
      "source": [
        "# IHS (Iterative Hessian Sketch) demo\n",
        "#### Start solving regression problems with the sketches\n",
        "\n",
        "The \"full sketch\" is the standard \"sketch-to-solve\" which is our baseline method.  We don't expect it to be that good in $\\|\\hat{x}-x_\\text{LS}\\|$ unless the data $b$ is almost entirely in the column space of $A$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_chnpN663Vth",
        "outputId": "fa894660-e799-4962-d2f9-3a33e0dc3667"
      },
      "source": [
        "print(f'\\nFull sketch')\n",
        "%time xFull = full_sketch( SA, Sb )\n",
        "err1, err2, err3 = errors(xFull)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )\n",
        "\n",
        "print(f'\\nPartial sketch')\n",
        "%time xPartial = partial_sketch( SA, A.T@b, printOutput=True, solver=0)\n",
        "err1, err2, err3 = errors(xPartial)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Full sketch\n",
            "CPU times: user 1.42 s, sys: 116 ms, total: 1.53 s\n",
            "Wall time: 849 ms\n",
            "\n",
            "\tErrors are 1.1e-02, 1.6e+02 and 4.4e-02\n",
            "\n",
            "Partial sketch\n",
            "Relative residual ||(SA)^T (SA)x - A^T b||/||A^T b|| is 1.08e-11\n",
            "CPU times: user 429 ms, sys: 138 ms, total: 567 ms\n",
            "Wall time: 302 ms\n",
            "\n",
            "\tErrors are 1.3e-01, 1.1e+02 and 1.6e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwRmxpmWeBOD",
        "outputId": "29a280e5-4f63-411b-e195-55122a4363ba"
      },
      "source": [
        "k   = 5  # number of iterations for Iterative Hessian Sketch\n",
        "\n",
        "def IHS(k=5):\n",
        "  mm  = m // k\n",
        "  xHat= np.zeros((N,1))\n",
        "  bHat= b.copy()  # important!!!\n",
        "  print(f'Iterative Hessian Sketch, dividing {m} total rows into {k} blocks of {mm}')\n",
        "  for i in range(k):\n",
        "    xx = partial_sketch( np.sqrt(m/mm)*SA[i*mm:(i+1)*mm,:], A.T@bHat )\n",
        "    rho = norm( A@xx-A@(xLS-xHat) )/norm(A@(xLS-xHat) )\n",
        "    xHat += xx\n",
        "    bHat -= A@xx\n",
        "    err1, err2, err3 = errors(xHat)\n",
        "    print(f'  Iter {i+1:2d}, contraction factor {rho:.2f}, errors {err1:5.2e}, {err2:5.2e}, {err3:5.2e}')\n",
        "  print(f'\\n\\n')\n",
        "\n",
        "IHS(1)\n",
        "\n",
        "IHS(5)\n",
        "\n",
        "IHS(8)\n",
        "\n",
        "IHS(10)\n",
        "\n",
        "IHS(20)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterative Hessian Sketch, dividing 20000 total rows into 1 blocks of 20000\n",
            "  Iter  1, contraction factor 0.16, errors 1.29e-01, 1.14e+02, 1.56e-01\n",
            "\n",
            "\n",
            "\n",
            "Iterative Hessian Sketch, dividing 20000 total rows into 5 blocks of 4000\n",
            "  Iter  1, contraction factor 0.43, errors 7.45e-01, 4.99e+02, 4.27e-01\n",
            "  Iter  2, contraction factor 0.46, errors 2.00e-01, 4.41e+02, 1.98e-01\n",
            "  Iter  3, contraction factor 0.45, errors 4.29e-02, 1.13e+02, 8.84e-02\n",
            "  Iter  4, contraction factor 0.44, errors 8.62e-03, 1.34e+02, 3.93e-02\n",
            "  Iter  5, contraction factor 0.46, errors 1.86e-03, 4.95e+00, 1.82e-02\n",
            "\n",
            "\n",
            "\n",
            "Iterative Hessian Sketch, dividing 20000 total rows into 8 blocks of 2500\n",
            "  Iter  1, contraction factor 0.66, errors 1.43e+00, 2.35e+02, 6.63e-01\n",
            "  Iter  2, contraction factor 0.65, errors 7.57e-01, 1.21e+03, 4.31e-01\n",
            "  Iter  3, contraction factor 0.67, errors 3.95e-01, 6.79e+02, 2.91e-01\n",
            "  Iter  4, contraction factor 0.67, errors 1.92e-01, 4.35e+01, 1.94e-01\n",
            "  Iter  5, contraction factor 0.62, errors 7.82e-02, 3.02e+02, 1.20e-01\n",
            "  Iter  6, contraction factor 0.59, errors 2.79e-02, 3.29e+01, 7.10e-02\n",
            "  Iter  7, contraction factor 0.64, errors 1.14e-02, 3.24e+01, 4.52e-02\n",
            "  Iter  8, contraction factor 0.60, errors 4.05e-03, 3.70e+01, 2.69e-02\n",
            "\n",
            "\n",
            "\n",
            "Iterative Hessian Sketch, dividing 20000 total rows into 10 blocks of 2000\n",
            "  Iter  1, contraction factor 0.85, errors 2.02e+00, 5.30e+02, 8.50e-01\n",
            "  Iter  2, contraction factor 0.83, errors 1.57e+00, 5.82e+02, 7.07e-01\n",
            "  Iter  3, contraction factor 0.82, errors 1.19e+00, 1.82e+03, 5.80e-01\n",
            "  Iter  4, contraction factor 0.77, errors 7.94e-01, 1.11e+03, 4.45e-01\n",
            "  Iter  5, contraction factor 0.85, errors 6.09e-01, 2.05e+02, 3.76e-01\n",
            "  Iter  6, contraction factor 0.74, errors 3.64e-01, 5.34e+02, 2.77e-01\n",
            "  Iter  7, contraction factor 0.78, errors 2.33e-01, 1.11e+02, 2.16e-01\n",
            "  Iter  8, contraction factor 0.80, errors 1.55e-01, 2.73e+02, 1.73e-01\n",
            "  Iter  9, contraction factor 0.84, errors 1.13e-01, 6.78e+00, 1.46e-01\n",
            "  Iter 10, contraction factor 0.79, errors 7.23e-02, 3.13e+02, 1.16e-01\n",
            "\n",
            "\n",
            "\n",
            "Iterative Hessian Sketch, dividing 20000 total rows into 20 blocks of 1000\n",
            "  Iter  1, contraction factor 2.05, errors 5.94e+00, 1.66e+02, 2.05e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.0805e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter  2, contraction factor 2.29, errors 1.48e+01, 3.72e+03, 4.70e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=9.0921e-17): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter  3, contraction factor 2.55, errors 3.91e+01, 2.00e+04, 1.20e+01\n",
            "  Iter  4, contraction factor 2.51, errors 9.94e+01, 3.04e+03, 3.00e+01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.07718e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter  5, contraction factor 2.24, errors 2.24e+02, 1.57e+05, 6.73e+01\n",
            "  Iter  6, contraction factor 2.35, errors 5.29e+02, 2.60e+05, 1.58e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=9.47894e-17): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter  7, contraction factor 1.99, errors 1.06e+03, 6.13e+05, 3.16e+02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.09473e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter  8, contraction factor 2.23, errors 2.36e+03, 4.77e+05, 7.05e+02\n",
            "  Iter  9, contraction factor 2.18, errors 5.14e+03, 2.47e+06, 1.54e+03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.03654e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter 10, contraction factor 2.21, errors 1.14e+04, 5.37e+06, 3.40e+03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.03947e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter 11, contraction factor 2.13, errors 2.42e+04, 1.16e+07, 7.22e+03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.08943e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter 12, contraction factor 2.39, errors 5.78e+04, 3.64e+07, 1.73e+04\n",
            "  Iter 13, contraction factor 2.14, errors 1.24e+05, 2.89e+07, 3.70e+04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.0368e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter 14, contraction factor 2.06, errors 2.55e+05, 8.42e+07, 7.61e+04\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=9.85846e-17): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter 15, contraction factor 2.33, errors 5.95e+05, 5.86e+07, 1.78e+05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=9.5671e-17): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter 16, contraction factor 2.26, errors 1.34e+06, 2.50e+08, 4.01e+05\n",
            "  Iter 17, contraction factor 2.52, errors 3.38e+06, 1.57e+09, 1.01e+06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.01733e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter 18, contraction factor 2.13, errors 7.21e+06, 1.96e+09, 2.15e+06\n",
            "  Iter 19, contraction factor 2.56, errors 1.85e+07, 2.30e+09, 5.52e+06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: LinAlgWarning: Ill-conditioned matrix (rcond=1.06876e-16): result may not be accurate.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Iter 20, contraction factor 2.32, errors 4.28e+07, 2.16e+10, 1.28e+07\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FECNYlw-BDi"
      },
      "source": [
        "### What happens if we re-use the same sketch in the iterative part?\n",
        "\n",
        "Our theory doesn't hold since the problem data $b$ is no longer a constant (it's a random variable that is dependent on the sketch $S$)\n",
        "\n",
        "But maybe it will work??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHYnljAkvyCf",
        "outputId": "f393270a-4223-40f4-89d3-0c825e3da13b"
      },
      "source": [
        "k   = 10  # number of iterations for Iterative Hessian Sketch\n",
        "xHat= np.zeros((N,1))\n",
        "bHat= b.copy()  # important!!!\n",
        "print('Iterative Hessian Sketch, RE-USING OLD SKETCHES!! This is off-label usage')\n",
        "for i in range(k):\n",
        "  xx = partial_sketch( SA, A.T@bHat ) # full SA matrix\n",
        "  rho = norm( A@xx-A@(xLS-xHat) )/norm(A@(xLS-xHat) )\n",
        "  xHat += xx\n",
        "  bHat -= A@xx\n",
        "  bHat = b.copy() - A@xHat  # if you're worried about accumulating error\n",
        "  err1, err2, err3 = errors(xHat)\n",
        "  print(f'  Iter {i+1:2d}, contraction factor {rho:.2f}, errors {err1:5.2e}, {err2:5.2e}, {err3:5.2e}')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterative Hessian Sketch, RE-USING OLD SKETCHES!! This is off-label usage\n",
            "  Iter  1, contraction factor 0.16, errors 1.29e-01, 1.14e+02, 1.56e-01\n",
            "  Iter  2, contraction factor 0.24, errors 7.91e-03, 7.09e+01, 3.76e-02\n",
            "  Iter  3, contraction factor 0.29, errors 6.50e-04, 1.46e+01, 1.08e-02\n",
            "  Iter  4, contraction factor 0.31, errors 6.33e-05, 6.70e+00, 3.36e-03\n",
            "  Iter  5, contraction factor 0.33, errors 6.76e-06, 1.63e+00, 1.10e-03\n",
            "  Iter  6, contraction factor 0.34, errors 7.62e-07, 6.04e-01, 3.69e-04\n",
            "  Iter  7, contraction factor 0.34, errors 8.90e-08, 1.70e-01, 1.26e-04\n",
            "  Iter  8, contraction factor 0.35, errors 1.06e-08, 5.84e-02, 4.36e-05\n",
            "  Iter  9, contraction factor 0.35, errors 1.30e-09, 1.80e-02, 1.52e-05\n",
            "  Iter 10, contraction factor 0.35, errors 1.60e-10, 6.06e-03, 5.34e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErWmWB6xjZGZ"
      },
      "source": [
        "# BLENDENPIK/LSRN Sketch-to-precondition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr-pHiwmVycp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d65a5ed-47db-4f4c-b424-a1671a254c74"
      },
      "source": [
        "from scipy.sparse.linalg import lsqr\n",
        "from scipy.sparse.linalg import LinearOperator, aslinearoperator, \n",
        "\n",
        "%time xHat, flag, iter, nrm = lsqr( A, b, show=True, iter_lim=int(1e2))[:4]\n",
        "\n",
        "err1, err2, err3 = errors(xHat)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "LSQR            Least-squares solution of  Ax = b\n",
            "The matrix A has   140000 rows  and      500 cols\n",
            "damp = 0.00000000000000e+00   calc_var =        0\n",
            "atol = 1.00e-08                 conlim = 1.00e+08\n",
            "btol = 1.00e-08               iter_lim =      100\n",
            " \n",
            "   Itn      x[0]       r1norm     r2norm   Compatible    LS      Norm A   Cond A\n",
            "     0  0.00000e+00   5.197e+07  5.197e+07    1.0e+00  1.1e-01\n",
            "     1  3.96508e-01   3.234e+07  3.234e+07    6.2e-01  5.5e-01   7.4e+06  1.0e+00\n",
            "     2  5.37958e-01   2.411e+07  2.411e+07    4.6e-01  3.0e-01   1.0e+07  2.3e+00\n",
            "     3  4.81235e-01   2.043e+07  2.043e+07    3.9e-01  1.8e-01   1.2e+07  3.7e+00\n",
            "     4  4.77483e-01   1.867e+07  1.867e+07    3.6e-01  1.1e-01   1.4e+07  5.2e+00\n",
            "     5  4.93412e-01   1.753e+07  1.753e+07    3.4e-01  9.6e-02   1.5e+07  7.0e+00\n",
            "     6  5.73973e-01   1.677e+07  1.677e+07    3.2e-01  6.6e-02   1.6e+07  9.0e+00\n",
            "     7  6.12775e-01   1.632e+07  1.632e+07    3.1e-01  6.0e-02   1.7e+07  1.1e+01\n",
            "     8  6.14310e-01   1.605e+07  1.605e+07    3.1e-01  4.2e-02   1.9e+07  1.3e+01\n",
            "     9  6.20342e-01   1.584e+07  1.584e+07    3.0e-01  3.2e-02   2.0e+07  1.5e+01\n",
            "    10  6.22547e-01   1.567e+07  1.567e+07    3.0e-01  2.9e-02   2.1e+07  1.8e+01\n",
            "    90  1.57779e+00   1.489e+07  1.489e+07    2.9e-01  5.4e-04   5.4e+07  4.7e+02\n",
            "    91  1.58632e+00   1.489e+07  1.489e+07    2.9e-01  3.2e-04   5.5e+07  4.9e+02\n",
            "    92  1.59311e+00   1.489e+07  1.489e+07    2.9e-01  4.4e-04   5.5e+07  4.9e+02\n",
            "    93  1.60054e+00   1.489e+07  1.489e+07    2.9e-01  2.6e-04   5.5e+07  5.0e+02\n",
            "    94  1.61448e+00   1.489e+07  1.489e+07    2.9e-01  4.6e-04   5.6e+07  5.1e+02\n",
            "    95  1.62202e+00   1.489e+07  1.489e+07    2.9e-01  3.9e-04   5.6e+07  5.2e+02\n",
            "    96  1.63382e+00   1.489e+07  1.489e+07    2.9e-01  2.9e-04   5.6e+07  5.3e+02\n",
            "    97  1.64089e+00   1.489e+07  1.489e+07    2.9e-01  4.4e-04   5.6e+07  5.4e+02\n",
            "    98  1.64535e+00   1.489e+07  1.489e+07    2.9e-01  3.1e-04   5.7e+07  5.5e+02\n",
            "    99  1.65034e+00   1.489e+07  1.489e+07    2.9e-01  3.6e-04   5.7e+07  5.6e+02\n",
            "   100  1.65451e+00   1.489e+07  1.489e+07    2.9e-01  2.2e-04   5.8e+07  5.6e+02\n",
            " \n",
            "LSQR finished\n",
            "The iteration limit has been reached                      \n",
            " \n",
            "istop =       7   r1norm = 1.5e+07   anorm = 5.8e+07   arnorm = 1.9e+11\n",
            "itn   =     100   r2norm = 1.5e+07   acond = 5.6e+02   xnorm  = 1.8e+01\n",
            " \n",
            "CPU times: user 18.4 s, sys: 623 ms, total: 19 s\n",
            "Wall time: 9.78 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbrcB055kMcu",
        "outputId": "2c68e5a5-4de3-4d81-cd3f-72064b6d0727"
      },
      "source": [
        "err1, err2, err3 = errors(xHat)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )\n",
        "print( f'\\tLSQR took {iter} iterations')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tErrors are 1.0e-03, 1.0e+00 and 1.3e-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xfF4DSLkf3i",
        "outputId": "e996a29e-5476-4061-9514-3163e5f07938"
      },
      "source": [
        "R = numpy.linalg.qr( SA, mode='r')\n",
        "Rinv_f = lambda x : scipy.linalg.solve_triangular( R, x)\n",
        "Rinv_t = lambda x : scipy.linalg.solve_triangular( R, x, trans='T')\n",
        "Rinv = LinearOperator((N,N), matvec = Rinv_f, rmatvec = Rinv_t)\n",
        "\n",
        "AR = aslinearoperator(A)@Rinv\n",
        "AR.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140000, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isALA4mvlQfg",
        "outputId": "c9557f33-6284-49a3-f076-4dc488240af1"
      },
      "source": [
        "%time zHat, flag, iter, nrm = lsqr( AR, b, show=True, atol=1e-16,btol=1e-16, iter_lim=int(1e2))[:4]\n",
        "xHat = Rinv_f(zHat)\n",
        "\n",
        "err1, err2, err3 = errors(xHat)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )\n",
        "print( f'\\tLSQR took {iter} iterations')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "LSQR            Least-squares solution of  Ax = b\n",
            "The matrix A has   140000 rows  and      500 cols\n",
            "damp = 0.00000000000000e+00   calc_var =        0\n",
            "atol = 1.00e-16                 conlim = 1.00e+08\n",
            "btol = 1.00e-16               iter_lim =      100\n",
            " \n",
            "   Itn      x[0]       r1norm     r2norm   Compatible    LS      Norm A   Cond A\n",
            "     0  0.00000e+00   5.197e+07  5.197e+07    1.0e+00  1.9e-08\n",
            "     1  7.77406e+06   1.658e+07  1.658e+07    3.2e-01  4.4e-01   1.0e+00  1.0e+00\n",
            "     2  8.01489e+06   1.491e+07  1.491e+07    2.9e-01  5.1e-02   1.5e+00  2.0e+00\n",
            "     3  8.02932e+06   1.487e+07  1.487e+07    2.9e-01  6.1e-03   1.8e+00  3.0e+00\n",
            "     4  8.03676e+06   1.487e+07  1.487e+07    2.9e-01  7.6e-04   2.1e+00  4.1e+00\n",
            "     5  8.03799e+06   1.487e+07  1.487e+07    2.9e-01  1.0e-04   2.3e+00  5.1e+00\n",
            "     6  8.03831e+06   1.487e+07  1.487e+07    2.9e-01  1.3e-05   2.5e+00  6.1e+00\n",
            "     7  8.03833e+06   1.487e+07  1.487e+07    2.9e-01  1.8e-06   2.7e+00  7.1e+00\n",
            "     8  8.03833e+06   1.487e+07  1.487e+07    2.9e-01  2.4e-07   2.9e+00  8.2e+00\n",
            "     9  8.03833e+06   1.487e+07  1.487e+07    2.9e-01  3.4e-08   3.1e+00  9.2e+00\n",
            "    10  8.03833e+06   1.487e+07  1.487e+07    2.9e-01  4.6e-09   3.3e+00  1.0e+01\n",
            "    18  8.03833e+06   1.487e+07  1.487e+07    2.9e-01  6.1e-16   4.4e+00  1.8e+01\n",
            "    19  8.03833e+06   1.487e+07  1.487e+07    2.9e-01  8.2e-17   4.5e+00  1.9e+01\n",
            " \n",
            "LSQR finished\n",
            "The least-squares solution is good enough, given atol     \n",
            " \n",
            "istop =       2   r1norm = 1.5e+07   anorm = 4.5e+00   arnorm = 5.5e-09\n",
            "itn   =      19   r2norm = 1.5e+07   acond = 1.9e+01   xnorm  = 5.0e+07\n",
            " \n",
            "CPU times: user 3.59 s, sys: 224 ms, total: 3.81 s\n",
            "Wall time: 2 s\n",
            "\n",
            "\tErrors are 1.1e-15, 1.8e-05 and 5.6e-10\n",
            "\tLSQR took 19 iterations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcXc5MkmlRfZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}