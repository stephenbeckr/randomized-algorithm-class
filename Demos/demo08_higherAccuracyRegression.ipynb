{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "demo08_higherAccuracyRegression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeUkgV6C3VDeCAMZtwrm3F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenbeckr/randomized-algorithm-class/blob/master/Demos/demo08_higherAccuracyRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcXAkDfs6OJD"
      },
      "source": [
        "# High-accuracy sketched least-squares\n",
        "\n",
        "Demo of the \n",
        "1. Iterative Hessian Sketch (IHS) cf. Pilanci and Wainwright; and of the \n",
        "2. preconditioned approaches (BLENDENPIK, LSRN)\n",
        "\n",
        "These are two methods to get high-accuracy l2 regression\n",
        "\n",
        "The goal is to approximate the solution of\n",
        "$$  \\min_{x} \\| Ax-b \\|_2^2 $$\n",
        "where $A$ is $M \\times N$ and we are assuming $M \\gg N$.\n",
        "\n",
        "Code: Stephen Becker, Oct 2021\n",
        "\n",
        "References:\n",
        "- \"Iterative Hessian Sketch: Fast and Accurate Solution\n",
        "Approximation for Constrained Least-Squares\" (Pilanci, Wainwright; JMLR 2016\n",
        "http://www.jmlr.org/papers/volume17/14-460/14-460.pdf )\n",
        "- \"Blendenpik: Supercharging LAPACK's Least-Squares Solver\" (Avron et al. 2010, https://epubs.siam.org/doi/abs/10.1137/090767911); \n",
        "- \"LSRN: A Parallel Iterative Solver for Strongly Over- or Underdetermined Systems\" (Meng et al. 2014, https://epubs.siam.org/doi/abs/10.1137/120866580 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-WX9lSc9XBx"
      },
      "source": [
        "import numpy as np\n",
        "import numpy.linalg\n",
        "from numpy.linalg import norm\n",
        "from numpy.random import default_rng\n",
        "rng = default_rng()\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import scipy.linalg\n",
        "\n",
        "# Download sketching code\n",
        "!wget -q https://raw.githubusercontent.com/stephenbeckr/randomized-algorithm-class/master/Code/sketch.py\n",
        "import sketch as sk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydwuiw9T4CsM"
      },
      "source": [
        "Setup some problem data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmciMdGD9q_v"
      },
      "source": [
        "M, N = int(14e4), int(5e2)\n",
        "# M, N = int(8e4), int(5e2)\n",
        "\n",
        "A   = rng.standard_normal( (M,N) )@np.diag(np.logspace(0,3,N))@(\n",
        "    rng.standard_normal((N,N) ) + 0.1*np.eye(N) )\n",
        "\n",
        "x   = rng.standard_normal( (N,1) )\n",
        "b   = A@x\n",
        "b   += 0.3*norm(b)/np.sqrt(M)*rng.standard_normal( (M,1) ) # add noise\n",
        "# (The larger the noise, the worse sketch-to-solve will perform )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAU-PEWV4Exa"
      },
      "source": [
        "#### Solve via standard direct solver, nothing randomized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTaJVxq2Ipmv",
        "outputId": "68423543-d4fd-42d8-8487-95884294c4aa"
      },
      "source": [
        "print(\"Solving via classical dense method\")\n",
        "%time xLS, residLS, rank, singVals = np.linalg.lstsq(A,b,rcond=None)\n",
        "\n",
        "print(f'Condition number of A is {singVals[0]/singVals[-1]:.3e}')\n",
        "\n",
        "AxLS = A@xLS\n",
        "# print(f'Relative residual ||Ax-b||/||b|| is {norm(AxLS-b)/norm(b):.2f}')\n",
        "print(f'Relative residual ||Ax-b||/||b|| is {np.sqrt(residLS[0])/norm(b):.2f}')\n",
        "# and use this to create error metrics\n",
        "def errors(x):\n",
        "  Ax  = np.ravel(A@x)\n",
        "\n",
        "  # Careful: do the ravel() since if we try (n,) - (n,1) then numpy\n",
        "  #   tries to broadcast this to something huge, and isn't what we want.\n",
        "  err1 = norm( Ax-np.ravel(b) )/norm(np.ravel(AxLS)-np.ravel(b))  - 1  # error in objective value\n",
        "  err2 = norm( np.ravel(x) - np.ravel(xLS) )/norm( xLS )     # error in x - xLS (relative error)\n",
        "  err3 = norm( Ax-np.ravel(AxLS) )/norm(AxLS)      # error in IHS analysis\n",
        "  return err1, err2, err3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solving via classical dense method\n",
            "CPU times: user 13 s, sys: 539 ms, total: 13.5 s\n",
            "Wall time: 7.36 s\n",
            "Condition number of A is 2.811e+05\n",
            "Relative residual ||Ax-b||/||b|| is 0.29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIhugSMX29EV"
      },
      "source": [
        "### Choose a sketch to use\n",
        "Usually choose FJLT, but could choose Gaussian (if problem isn't too big) or CountSketch (if problem is huge)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTWGiD0gZa4t",
        "outputId": "590ce13c-ada7-49ea-b735-25d291712a6b"
      },
      "source": [
        "%%time\n",
        "m   = 40*N  # sketch size\n",
        "print(f\"m is {m}, M is {M}, N is {N}\")\n",
        "\n",
        "if M < 1e4 and False:\n",
        "  # This runs out of memory if M is too large\n",
        "  S   = sk.Gaussian( (m,M) )\n",
        "  print('Using a Gaussian sketch')\n",
        "\n",
        "elif False:\n",
        "  # == Use a count-sketch:\n",
        "  S   = sk.Count( (m,M) )\n",
        "  print('Using a Count sketch')\n",
        "\n",
        "else:\n",
        "  # == ... or try a FJLT ...\n",
        "  S   = sk.FJLT( (m,M) )\n",
        "  print('Using a FJLT sketch')\n",
        "\n",
        "SA  = S@A\n",
        "Sb  = S@b\n",
        "print(f'||Sb||/||b|| is {norm(Sb)/norm(b):.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m is 20000, M is 140000, N is 500\n",
            "Using a FJLT sketch\n",
            "||Sb||/||b|| is 1.0031\n",
            "CPU times: user 3.43 s, sys: 210 ms, total: 3.64 s\n",
            "Wall time: 3.65 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eLg0IALaPIa"
      },
      "source": [
        "def full_sketch( SA, Sb, cond=1e-12,columnVec = True):\n",
        "  \"\"\" SA should be S@A and Sb should be S@b \n",
        "  Solves  min_x || S(Ax-b) ||_2 \"\"\"\n",
        "  # return np.linalg.lstsq(SA,Sb,rcond=None)[0]\n",
        "  x = scipy.linalg.lstsq(SA,Sb,cond=cond,lapack_driver='gelsd')[0]\n",
        "  if columnVec:\n",
        "    return np.reshape( x, (-1,1) ) # make sure it is (n,1) not (n,)\n",
        "  else:\n",
        "    # it will have the same shape convention as Sb, so if Sb is (m,1)\n",
        "    #   then x will be (n,1) and if Sb is (m,) then x will be (n,)\n",
        "    return x\n",
        "\n",
        "def partial_sketch(SA,Atb, printOutput=False, solver=0, reg=0,columnVec = True):\n",
        "  \"\"\" SA should be S@A and Atb should be A.T@b \n",
        "  Solves min_x ||SAx||_2^2 - 2<x,A^T b>,\n",
        "  i.e., x = ( (SA)^T SA )^{-1} A^T b\n",
        "  \n",
        "  Solver choices:\n",
        "    solver=0  is using scipy.linalg.solve on (SA)^T(SA) which is fast\n",
        "      but less accurate since it square the condition number of SA,\n",
        "      so recommended for all but the most ill-conditioned problems.\n",
        "      Set reg>0 (e.g., reg=1e-10) to add a small amount of regularization\n",
        "      (relative to the largest singular value)\n",
        "\n",
        "    solver=1  uses a pivoted QR decomposition and is more appropriate when\n",
        "      the matrix is ill-conditioned, but a bit slower.  `reg` has no effect\n",
        "\n",
        "    solver=2  uses an unpivoted QR decomposition and is a bit faster than\n",
        "      solver=1.  `reg` has no effect\n",
        "   \"\"\"\n",
        "  \n",
        "  if solver == 0:\n",
        "    # == Below is the basic code that fails if ill-conditioned: ==\n",
        "    if reg is None or reg==0:\n",
        "      x = scipy.linalg.solve(  SA.T@SA, Atb, assume_a='pos')\n",
        "    else:\n",
        "      # == Slightly better for ill-conditioned, still not good at all though ==\n",
        "      G = SA.T@SA\n",
        "      normG = norm(G,ord=2)\n",
        "      if printOutput:\n",
        "        print(f\"||G|| is {normG:.2e} and has condition number {np.linalg.cond(G):.2e}\")\n",
        "      # Add in a bit of regularization:\n",
        "      x = scipy.linalg.solve(  G + reg*normG*np.eye(N), Atb, assume_a='pos')\n",
        "  elif solver == 1:\n",
        "    # == The above still has problems when ill-conditioned. Let's do SA = QR\n",
        "    # Then G = R^T R and we can do back substitution\n",
        "    R, perm = scipy.linalg.qr( SA, mode='r', pivoting=True )\n",
        "    R = R[:N,:] # Annoyingly, in mode='r', R is rectangular not square, but 'economic' mode is slow.\n",
        "\n",
        "    y = scipy.linalg.solve_triangular( R, Atb[perm], trans='T')\n",
        "    x = np.zeros_like(y)\n",
        "    x[perm] = scipy.linalg.solve_triangular( R, y, trans='N')\n",
        "\n",
        "  elif solver == 2:\n",
        "    # == Same as solver==1 but no pivoting, and use numpy not scipy\n",
        "    #  since it gives us thin factorization (but doesn't support pivoting)\n",
        "    R = numpy.linalg.qr( SA, mode='r')\n",
        "    y = scipy.linalg.solve_triangular( R, Atb, trans='T')\n",
        "    x = scipy.linalg.solve_triangular( R, y, trans='N')\n",
        "\n",
        "  if printOutput:\n",
        "    res = norm( SA.T@(SA@x) - Atb )/norm(Atb)\n",
        "    print(f'Relative residual ||(SA)^T (SA)x - A^T b||/||A^T b|| is {res:.2e}')\n",
        "\n",
        "  if columnVec:\n",
        "    return np.reshape( x, (-1,1) ) # make sure it is (n,1) not (n,)\n",
        "  else:\n",
        "    # it will have the same shape convention as Sb, so if Sb is (m,1)\n",
        "    #   then x will be (n,1) and if Sb is (m,) then x will be (n,)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueJ8T0iC3WVy"
      },
      "source": [
        "# IHS (Iterative Hessian Sketch) demo\n",
        "#### Start solving regression problems with the sketches\n",
        "\n",
        "The \"full sketch\" is the standard \"sketch-to-solve\" which is our baseline method.  We don't expect it to be that good in $\\|\\hat{x}-x_\\text{LS}\\|$ unless the data $b$ is almost entirely in the column space of $A$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_chnpN663Vth",
        "outputId": "140c5a5f-c4d3-4413-bddc-0986f6a8b544"
      },
      "source": [
        "print(f'\\nFull sketch')\n",
        "%time xFull = full_sketch( SA, Sb )\n",
        "err1, err2, err3 = errors(xFull)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )\n",
        "\n",
        "print(f'\\nPartial sketch')\n",
        "%time xPartial = partial_sketch( SA, A.T@b, printOutput=True, solver=0)\n",
        "err1, err2, err3 = errors(xPartial)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Full sketch\n",
            "CPU times: user 1.55 s, sys: 133 ms, total: 1.68 s\n",
            "Wall time: 962 ms\n",
            "\n",
            "\tErrors are 1.1e-02, 6.4e+00 and 4.4e-02\n",
            "\n",
            "Partial sketch\n",
            "Relative residual ||(SA)^T (SA)x - A^T b||/||A^T b|| is 1.59e-13\n",
            "CPU times: user 491 ms, sys: 140 ms, total: 631 ms\n",
            "Wall time: 339 ms\n",
            "\n",
            "\tErrors are 1.3e-01, 1.8e+01 and 1.6e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwRmxpmWeBOD",
        "outputId": "01afdfa0-fe28-4a68-82e8-222107b3f754"
      },
      "source": [
        "k   = 5  # number of iterations for Iterative Hessian Sketch\n",
        "\n",
        "def IHS(k=5):\n",
        "  mm  = m // k\n",
        "  xHat= np.zeros((N,1))\n",
        "  bHat= b.copy()  # important!!!\n",
        "  print(f'Iterative Hessian Sketch, dividing {m} total rows into {k} blocks of {mm}')\n",
        "  for i in range(k):\n",
        "    xx = partial_sketch( np.sqrt(m/mm)*SA[i*mm:(i+1)*mm,:], A.T@bHat )\n",
        "    rho = norm( A@xx-A@(xLS-xHat) )/norm(A@(xLS-xHat) )\n",
        "    xHat += xx\n",
        "    bHat -= A@xx\n",
        "    err1, err2, err3 = errors(xHat)\n",
        "    print(f'  Iter {i+1:2d}, contraction factor {rho:.2f}, errors {err1:5.2e}, {err2:5.2e}, {err3:5.2e}')\n",
        "  print(f'\\n\\n')\n",
        "\n",
        "IHS(1)\n",
        "\n",
        "IHS(5)\n",
        "\n",
        "IHS(8)\n",
        "\n",
        "IHS(10)\n",
        "\n",
        "IHS(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterative Hessian Sketch, dividing 20000 total rows into 1 blocks of 20000\n",
            "  Iter  1, contraction factor 0.16, errors 1.29e-01, 1.81e+01, 1.57e-01\n",
            "\n",
            "\n",
            "\n",
            "Iterative Hessian Sketch, dividing 20000 total rows into 5 blocks of 4000\n",
            "  Iter  1, contraction factor 0.47, errors 8.74e-01, 3.00e+01, 4.74e-01\n",
            "  Iter  2, contraction factor 0.44, errors 2.15e-01, 7.34e+01, 2.07e-01\n",
            "  Iter  3, contraction factor 0.46, errors 4.86e-02, 9.08e+00, 9.44e-02\n",
            "  Iter  4, contraction factor 0.39, errors 7.58e-03, 8.74e+00, 3.69e-02\n",
            "  Iter  5, contraction factor 0.45, errors 1.52e-03, 4.96e+00, 1.65e-02\n",
            "\n",
            "\n",
            "\n",
            "Iterative Hessian Sketch, dividing 20000 total rows into 8 blocks of 2500\n",
            "  Iter  1, contraction factor 0.69, errors 1.52e+00, 1.06e+02, 6.94e-01\n",
            "  Iter  2, contraction factor 0.67, errors 8.42e-01, 2.79e+01, 4.63e-01\n",
            "  Iter  3, contraction factor 0.59, errors 3.59e-01, 2.90e+01, 2.75e-01\n",
            "  Iter  4, contraction factor 0.71, errors 1.95e-01, 5.53e+01, 1.96e-01\n",
            "  Iter  5, contraction factor 0.63, errors 8.28e-02, 9.60e+00, 1.24e-01\n",
            "  Iter  6, contraction factor 0.63, errors 3.32e-02, 9.76e+00, 7.77e-02\n",
            "  Iter  7, contraction factor 0.67, errors 1.49e-02, 1.46e+01, 5.19e-02\n",
            "  Iter  8, contraction factor 0.60, errors 5.32e-03, 2.91e+00, 3.09e-02\n",
            "\n",
            "\n",
            "\n",
            "Iterative Hessian Sketch, dividing 20000 total rows into 10 blocks of 2000\n",
            "  Iter  1, contraction factor 0.83, errors 1.93e+00, 2.15e+02, 8.26e-01\n",
            "  Iter  2, contraction factor 0.84, errors 1.52e+00, 1.12e+02, 6.92e-01\n",
            "  Iter  3, contraction factor 0.74, errors 9.86e-01, 1.33e+02, 5.14e-01\n",
            "  Iter  4, contraction factor 0.76, errors 6.42e-01, 2.20e+02, 3.90e-01\n",
            "  Iter  5, contraction factor 0.87, errors 5.16e-01, 1.34e+02, 3.41e-01\n",
            "  Iter  6, contraction factor 0.82, errors 3.68e-01, 7.38e+01, 2.79e-01\n",
            "  Iter  7, contraction factor 0.80, errors 2.46e-01, 3.24e+01, 2.23e-01\n",
            "  Iter  8, contraction factor 0.89, errors 1.97e-01, 1.49e+01, 1.97e-01\n",
            "  Iter  9, contraction factor 0.85, errors 1.45e-01, 3.70e+01, 1.67e-01\n",
            "  Iter 10, contraction factor 0.77, errors 8.84e-02, 1.34e+01, 1.29e-01\n",
            "\n",
            "\n",
            "\n",
            "Iterative Hessian Sketch, dividing 20000 total rows into 20 blocks of 1000\n",
            "  Iter  1, contraction factor 2.06, errors 5.96e+00, 9.97e+01, 2.06e+00\n",
            "  Iter  2, contraction factor 2.66, errors 1.74e+01, 5.66e+02, 5.50e+00\n",
            "  Iter  3, contraction factor 2.23, errors 3.99e+01, 4.61e+03, 1.23e+01\n",
            "  Iter  4, contraction factor 2.24, errors 9.05e+01, 4.75e+03, 2.74e+01\n",
            "  Iter  5, contraction factor 2.13, errors 1.94e+02, 2.57e+03, 5.84e+01\n",
            "  Iter  6, contraction factor 2.08, errors 4.04e+02, 1.13e+04, 1.21e+02\n",
            "  Iter  7, contraction factor 2.33, errors 9.43e+02, 1.82e+04, 2.82e+02\n",
            "  Iter  8, contraction factor 2.05, errors 1.93e+03, 4.65e+04, 5.78e+02\n",
            "  Iter  9, contraction factor 2.34, errors 4.52e+03, 1.14e+05, 1.35e+03\n",
            "  Iter 10, contraction factor 2.48, errors 1.12e+04, 1.75e+05, 3.35e+03\n",
            "  Iter 11, contraction factor 2.11, errors 2.36e+04, 9.45e+05, 7.07e+03\n",
            "  Iter 12, contraction factor 1.95, errors 4.61e+04, 1.49e+06, 1.38e+04\n",
            "  Iter 13, contraction factor 2.39, errors 1.10e+05, 1.89e+06, 3.30e+04\n",
            "  Iter 14, contraction factor 1.91, errors 2.11e+05, 4.33e+06, 6.31e+04\n",
            "  Iter 15, contraction factor 2.15, errors 4.52e+05, 2.33e+07, 1.35e+05\n",
            "  Iter 16, contraction factor 2.22, errors 1.01e+06, 3.45e+07, 3.01e+05\n",
            "  Iter 17, contraction factor 2.18, errors 2.20e+06, 2.76e+07, 6.57e+05\n",
            "  Iter 18, contraction factor 2.44, errors 5.36e+06, 6.21e+08, 1.61e+06\n",
            "  Iter 19, contraction factor 2.19, errors 1.17e+07, 3.49e+08, 3.51e+06\n",
            "  Iter 20, contraction factor 2.35, errors 2.76e+07, 1.35e+09, 8.25e+06\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FECNYlw-BDi"
      },
      "source": [
        "### What happens if we re-use the same sketch in the iterative part?\n",
        "\n",
        "Our theory doesn't hold since the problem data $b$ is no longer a constant (it's a random variable that is dependent on the sketch $S$)\n",
        "\n",
        "But maybe it will work??\n",
        "- actually, this idea (or a variant) is in [Faster Least Squares Optimization\n",
        "](https://arxiv.org/abs/1911.02675) by Lacotte and Pilanci, 2019\n",
        "- See also this journal version [Optimal Randomized First-Order Methods for Least-Squares Problems](http://proceedings.mlr.press/v119/lacotte20a.html) by Lacotte and Pilanci, ICML 2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHYnljAkvyCf",
        "outputId": "bcce2450-1a26-41cd-c43b-c5513747bcd2"
      },
      "source": [
        "k   = 10  # number of iterations for Iterative Hessian Sketch\n",
        "xHat= np.zeros((N,1))\n",
        "bHat= b.copy()  # important!!!\n",
        "print('Iterative Hessian Sketch, RE-USING OLD SKETCHES!! This is off-label usage')\n",
        "for i in range(k):\n",
        "  xx = partial_sketch( SA, A.T@bHat ) # full SA matrix\n",
        "  rho = norm( A@xx-A@(xLS-xHat) )/norm(A@(xLS-xHat) )\n",
        "  xHat += xx\n",
        "  bHat -= A@xx\n",
        "  bHat = b.copy() - A@xHat  # if you're worried about accumulating error\n",
        "  err1, err2, err3 = errors(xHat)\n",
        "  print(f'  Iter {i+1:2d}, contraction factor {rho:.2f}, errors {err1:5.2e}, {err2:5.2e}, {err3:5.2e}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iterative Hessian Sketch, RE-USING OLD SKETCHES!! This is off-label usage\n",
            "  Iter  1, contraction factor 0.16, errors 1.29e-01, 1.81e+01, 1.57e-01\n",
            "  Iter  2, contraction factor 0.24, errors 7.94e-03, 3.35e+00, 3.78e-02\n",
            "  Iter  3, contraction factor 0.28, errors 6.37e-04, 1.01e+00, 1.07e-02\n",
            "  Iter  4, contraction factor 0.31, errors 6.01e-05, 3.40e-01, 3.28e-03\n",
            "  Iter  5, contraction factor 0.32, errors 6.24e-06, 1.25e-01, 1.06e-03\n",
            "  Iter  6, contraction factor 0.33, errors 6.91e-07, 4.42e-02, 3.52e-04\n",
            "  Iter  7, contraction factor 0.34, errors 7.97e-08, 1.66e-02, 1.20e-04\n",
            "  Iter  8, contraction factor 0.34, errors 9.48e-09, 5.96e-03, 4.12e-05\n",
            "  Iter  9, contraction factor 0.35, errors 1.15e-09, 2.19e-03, 1.44e-05\n",
            "  Iter 10, contraction factor 0.35, errors 1.43e-10, 7.89e-04, 5.06e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErWmWB6xjZGZ"
      },
      "source": [
        "# BLENDENPIK/LSRN Sketch-to-precondition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9wcVYl4uZHS"
      },
      "source": [
        "Let's start by using a standard linear solver for least squares, [`lsqr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.linalg.lsqr.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr-pHiwmVycp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "013bb63c-811b-46de-bf40-f7bb439a00c4"
      },
      "source": [
        "from scipy.sparse.linalg import lsqr\n",
        "from scipy.sparse.linalg import LinearOperator, aslinearoperator\n",
        "\n",
        "%time xHat, flag, iter, nrm = lsqr( A, b, show=True, iter_lim=int(1e2))[:4]\n",
        "\n",
        "err1, err2, err3 = errors(xHat)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "LSQR            Least-squares solution of  Ax = b\n",
            "The matrix A has   140000 rows  and      500 cols\n",
            "damp = 0.00000000000000e+00   calc_var =        0\n",
            "atol = 1.00e-08                 conlim = 1.00e+08\n",
            "btol = 1.00e-08               iter_lim =      100\n",
            " \n",
            "   Itn      x[0]       r1norm     r2norm   Compatible    LS      Norm A   Cond A\n",
            "     0  0.00000e+00   4.841e+07  4.841e+07    1.0e+00  1.2e-01\n",
            "     1  2.63044e-01   2.663e+07  2.663e+07    5.5e-01  5.3e-01   7.1e+06  1.0e+00\n",
            "     2  2.76601e-01   2.120e+07  2.120e+07    4.4e-01  2.6e-01   9.7e+06  2.2e+00\n",
            "     3  3.78793e-01   1.844e+07  1.844e+07    3.8e-01  1.9e-01   1.1e+07  3.6e+00\n",
            "     4  4.53280e-01   1.716e+07  1.716e+07    3.5e-01  1.2e-01   1.3e+07  5.2e+00\n",
            "     5  4.84351e-01   1.626e+07  1.626e+07    3.4e-01  1.0e-01   1.5e+07  7.0e+00\n",
            "     6  4.62640e-01   1.560e+07  1.560e+07    3.2e-01  7.2e-02   1.7e+07  9.1e+00\n",
            "     7  4.91588e-01   1.516e+07  1.516e+07    3.1e-01  4.7e-02   1.8e+07  1.1e+01\n",
            "     8  4.97109e-01   1.493e+07  1.493e+07    3.1e-01  4.2e-02   1.9e+07  1.3e+01\n",
            "     9  5.43303e-01   1.475e+07  1.475e+07    3.0e-01  3.4e-02   2.0e+07  1.5e+01\n",
            "    10  5.98428e-01   1.461e+07  1.461e+07    3.0e-01  2.9e-02   2.1e+07  1.8e+01\n",
            "    90  1.50038e+00   1.390e+07  1.390e+07    2.9e-01  3.7e-04   5.6e+07  4.8e+02\n",
            "    91  1.50449e+00   1.390e+07  1.390e+07    2.9e-01  3.8e-04   5.6e+07  4.9e+02\n",
            "    92  1.50642e+00   1.390e+07  1.390e+07    2.9e-01  4.3e-04   5.6e+07  4.9e+02\n",
            "    93  1.50943e+00   1.390e+07  1.390e+07    2.9e-01  3.1e-04   5.6e+07  5.0e+02\n",
            "    94  1.51393e+00   1.390e+07  1.390e+07    2.9e-01  2.6e-04   5.6e+07  5.1e+02\n",
            "    95  1.51696e+00   1.390e+07  1.390e+07    2.9e-01  3.7e-04   5.7e+07  5.2e+02\n",
            "    96  1.51875e+00   1.390e+07  1.390e+07    2.9e-01  2.4e-04   5.7e+07  5.2e+02\n",
            "    97  1.52092e+00   1.390e+07  1.390e+07    2.9e-01  3.8e-04   5.7e+07  5.3e+02\n",
            "    98  1.52391e+00   1.390e+07  1.390e+07    2.9e-01  2.5e-04   5.8e+07  5.4e+02\n",
            "    99  1.52661e+00   1.390e+07  1.390e+07    2.9e-01  3.4e-04   5.8e+07  5.4e+02\n",
            "   100  1.52842e+00   1.390e+07  1.390e+07    2.9e-01  2.6e-04   5.8e+07  5.5e+02\n",
            " \n",
            "LSQR finished\n",
            "The iteration limit has been reached                      \n",
            " \n",
            "istop =       7   r1norm = 1.4e+07   anorm = 5.8e+07   arnorm = 2.1e+11\n",
            "itn   =     100   r2norm = 1.4e+07   acond = 5.5e+02   xnorm  = 1.7e+01\n",
            " \n",
            "CPU times: user 19.5 s, sys: 707 ms, total: 20.2 s\n",
            "Wall time: 10.5 s\n",
            "\n",
            "\tErrors are 1.1e-03, 1.0e+00 and 1.4e-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0lj8P7fvFur"
      },
      "source": [
        "Now let's precondition.  We use the `R` from the thin `QR` decomposition of the *sketched* matrix $SA$.\n",
        "\n",
        "Then, we want to solve the system\n",
        "$$\n",
        "\\min_z || AR^{-1}z - b ||^2\n",
        "$$\n",
        "where we've done the change-of-variables $x=R^{-1}z$\n",
        "so after solving the system for $z$, we do one final conversion back to $x$.\n",
        "\n",
        "We need to give `scipy` a linear operator that can multiply $x\\mapsto AR^{-1}x$, which is easy using the `LinearOperator` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xfF4DSLkf3i",
        "outputId": "812d7375-32ff-4081-8bdd-364429a98fd9"
      },
      "source": [
        "%time R = numpy.linalg.qr( SA, mode='r')\n",
        "Rinv_f = lambda x : scipy.linalg.solve_triangular( R, x)\n",
        "Rinv_t = lambda x : scipy.linalg.solve_triangular( R, x, trans='T')\n",
        "Rinv = LinearOperator((N,N), matvec = Rinv_f, rmatvec = Rinv_t)\n",
        "\n",
        "AR = aslinearoperator(A)@Rinv\n",
        "AR.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.34 s, sys: 206 ms, total: 1.55 s\n",
            "Wall time: 880 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(140000, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fWI1c5yvkFL"
      },
      "source": [
        "### Solving the preconditioned system\n",
        "Now we solve via `lsqr` and see if it converges more quickly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isALA4mvlQfg",
        "outputId": "711c6fc7-d42c-4470-daa8-bd758e5eb0b1"
      },
      "source": [
        "%time zHat, flag, iter, nrm = lsqr( AR, b, show=True, atol=1e-16,btol=1e-16, iter_lim=10)[:4]\n",
        "xHat = Rinv_f(zHat)\n",
        "\n",
        "err1, err2, err3 = errors(xHat)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )\n",
        "print( f'\\tLSQR took {iter} iterations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "LSQR            Least-squares solution of  Ax = b\n",
            "The matrix A has   140000 rows  and      500 cols\n",
            "damp = 0.00000000000000e+00   calc_var =        0\n",
            "atol = 1.00e-16                 conlim = 1.00e+08\n",
            "btol = 1.00e-16               iter_lim =       10\n",
            " \n",
            "   Itn      x[0]       r1norm     r2norm   Compatible    LS      Norm A   Cond A\n",
            "     0  0.00000e+00   4.841e+07  4.841e+07    1.0e+00  2.0e-08\n",
            "     1  5.95586e+06   1.545e+07  1.545e+07    3.2e-01  4.4e-01   1.0e+00  1.0e+00\n",
            "     2  5.88502e+06   1.392e+07  1.392e+07    2.9e-01  5.2e-02   1.5e+00  2.0e+00\n",
            "     3  5.91503e+06   1.388e+07  1.388e+07    2.9e-01  5.8e-03   1.8e+00  3.0e+00\n",
            "     4  5.92222e+06   1.388e+07  1.388e+07    2.9e-01  7.1e-04   2.1e+00  4.1e+00\n",
            "     5  5.92247e+06   1.388e+07  1.388e+07    2.9e-01  9.3e-05   2.3e+00  5.1e+00\n",
            "     6  5.92267e+06   1.388e+07  1.388e+07    2.9e-01  1.3e-05   2.5e+00  6.1e+00\n",
            "     7  5.92271e+06   1.388e+07  1.388e+07    2.9e-01  1.7e-06   2.7e+00  7.1e+00\n",
            "     8  5.92271e+06   1.388e+07  1.388e+07    2.9e-01  2.2e-07   2.9e+00  8.1e+00\n",
            "     9  5.92271e+06   1.388e+07  1.388e+07    2.9e-01  3.3e-08   3.1e+00  9.2e+00\n",
            "    10  5.92271e+06   1.388e+07  1.388e+07    2.9e-01  4.5e-09   3.3e+00  1.0e+01\n",
            " \n",
            "LSQR finished\n",
            "The iteration limit has been reached                      \n",
            " \n",
            "istop =       7   r1norm = 1.4e+07   anorm = 3.3e+00   arnorm = 2.1e-01\n",
            "itn   =      10   r2norm = 1.4e+07   acond = 1.0e+01   xnorm  = 4.7e+07\n",
            " \n",
            "CPU times: user 2.09 s, sys: 205 ms, total: 2.3 s\n",
            "Wall time: 1.25 s\n",
            "\n",
            "\tErrors are 0.0e+00, 5.1e-07 and 4.4e-09\n",
            "\tLSQR took 10 iterations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcXc5MkmlRfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09487409-3d39-4dce-b5bc-fb9fbd682152"
      },
      "source": [
        "# Find the condition number. This may be slow...\n",
        "AR_explicit = AR@np.eye(N)\n",
        "cnd         = np.linalg.cond( AR_explicit )\n",
        "print(f'Condition number of AR^{-1} is {cnd:.2e}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Condition number of AR^-1 is 1.34e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q85GaHeI9aZY"
      },
      "source": [
        "### Repeat for using the Count Sketch\n",
        "Let's see how fast we are"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbD5XTJk4a6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a955d0c4-3c3d-4cef-c62e-7d0972ead6e1"
      },
      "source": [
        "%%time \n",
        "S   = sk.Count( (m,M) )\n",
        "R   = numpy.linalg.qr( S@A, mode='r')\n",
        "\n",
        "Rinv_f = lambda x : scipy.linalg.solve_triangular( R, x)\n",
        "Rinv_t = lambda x : scipy.linalg.solve_triangular( R, x, trans='T')\n",
        "Rinv   = LinearOperator((N,N), matvec = Rinv_f, rmatvec = Rinv_t)\n",
        "AR     = aslinearoperator(A)@Rinv\n",
        "\n",
        "\n",
        "zHat, flag, iter, nrm = lsqr( AR, b, show=False,iter_lim=7)[:4]\n",
        "xHat = Rinv_f(zHat)\n",
        "\n",
        "err1, err2, err3 = errors(xHat)\n",
        "print( f'\\n\\tErrors are {err1:.1e}, {err2:.1e} and {err3:.1e}' )\n",
        "print( f'\\tLSQR took {iter} iterations')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\tErrors are 4.2e-11, 7.0e-04 and 2.7e-06\n",
            "\tLSQR took 7 iterations\n",
            "CPU times: user 3.16 s, sys: 176 ms, total: 3.33 s\n",
            "Wall time: 1.92 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvpP99qz9xsK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}